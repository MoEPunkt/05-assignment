---
title: "Erdt_Moritz_AssignmentV"
author: "Moritz Erdt"
date: "16.02.2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set (echo = TRUE)
library(httr)
library(rlist)
library(jsonlite)
library(tidyverse)
library(maps)

source("C:/Users/morit/Google Drive/Master/studium/01_WS2021/data-science-project-management/tutorial/05-assignment/api_key.R")
```

## General Note

This is the solution for the fourth assignment in Data Science Project 
Management. It has been written by myself without any help or cooperation.

## 1. Setting up a new GitHub repository
A GitHub repository has been created to document the solution properly.
I can be seen [here](https://github.com/MoEPunkt/05-assignment.git).

save searchstrings so  we can just insert them into a function
use paste ()
source api-script


## 2. Getting to know the API

rate limit 5000
5 requests per second

## 3. Interacting with the API - the basics

default value of the page size of the response : 20

note: https://developer.ticketmaster.com/products-and-docs/apis/discovery-api/v2/#search-venues-v2
```{r germanVenues}

first.quest <- function(country, key) {
  # Gets the response from Ticketmaster.com and returns it
  venues <- GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
                query = list(locale = "*",
                             countryCode = country,
                             apikey = key))
  venues
}

first.df <- function(venues, content_venues) {
  # Processes the response from Ticketmaster.com
  json_parsed_search <- fromJSON(content(venues, as = "text"))[["_embedded"]][["venues"]]
  
  n = as.numeric(content_venues$page$size)
  
  venue_data <-
    data.frame(
      name = character(n),
      city = character(n),
      postalCode = character(n),
      address = character(n),
      url = character(n),
      longitude = double(n),
      latitude = double (n)
    )
  
  venue_data[, 1] <- json_parsed_search$name
  venue_data[, 2] <- json_parsed_search$city$name
  venue_data[, 3] <- json_parsed_search$postalCode
  venue_data[, 4] <- json_parsed_search$address$line1
  venue_data[, 5] <- json_parsed_search$url
  venue_data[, 6] <- as.double(json_parsed_search$location$longitude)
  venue_data[, 7] <- as.double(json_parsed_search$location$latitude)
  
  venue_data
}


country <- "DE"

response_1 <- first.quest(country, tm_key)
content_1 <- content(response_1)

venue_data_1 <- first.df(response_1, content_1)

glimpse(venue_data_1)
``` 

The response object delivers a list of length 3. The element "_embedded"
contains the 20 venues, that are returned. The element "links" contains pointers
to the current side as well as to the prior, the next and the last page. The 
element "page" specifies the response: the returned page consists of 20 items,
in total there are 12238 elements that are stored on 612 pages.

From trying to set `size = 12238`, we receive the message, that the spezified 
size of elements needs to be less than 500.

Note: replace explicit numbers with variables

## 4 Interacting with the API - advanced
The request from exercise 3 did not return all event locations in Germany. In
total, there are 12238 venues that are stored on multiple pages.
The pages can be iterated by using the parameter `page`.

```{r germanVenues500}

second.quest <- function(country, size, key){

  venues <- GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
                query = list(locale = "*",
                             size = size,
                             countryCode = country,
                             apikey = key))
  
  content_venues <- content(venues)
  
  n = as.numeric(content_venues$page$totalElements)
  l = as.numeric(content_venues$page$totalPages)
  
  venue_data <-
    data.frame(
      name = character(n),
      city = character(n),
      postalCode = character(n),
      address = character(n),
      url = character(n),
      longitude = double(n),
      latitude = double (n)
    )
  
  for (i in 1:l){
    venues <- GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
                query = list(locale = "*",
                             size = size,
                             countryCode = country,
                             apikey = key,
                             page = i-1))
    json_parsed_search <- fromJSON(content(venues, as = "text"))[["_embedded"]][["venues"]]
    
    rows <- as.numeric(nrow(json_parsed_search))
    
    if (i == l) {
      venue_data[((i-1)*500 + 1):((i-1)*500 + rows), 1] <- json_parsed_search$name
      venue_data[((i-1)*500 + 1):((i-1)*500 + rows), 2] <- json_parsed_search$city$name
      venue_data[((i-1)*500 + 1):((i-1)*500 + rows), 3] <- json_parsed_search$postalCode
      venue_data[((i-1)*500 + 1):((i-1)*500 + rows), 4] <- json_parsed_search$address$line1
      venue_data[((i-1)*500 + 1):((i-1)*500 + rows), 5] <- json_parsed_search$url
      venue_data[((i-1)*500 + 1):((i-1)*500 + rows), 6] <- as.double(json_parsed_search$location$longitude)
      venue_data[((i-1)*500 + 1):((i-1)*500 + rows), 7] <- as.double(json_parsed_search$location$latitude)
    } else {
      venue_data[((i-1)*500 + 1):(i*rows), 1] <- json_parsed_search$name
      venue_data[((i-1)*500 + 1):(i*rows), 2] <- json_parsed_search$city$name
      venue_data[((i-1)*500 + 1):(i*rows), 3] <- json_parsed_search$postalCode
      venue_data[((i-1)*500 + 1):(i*rows), 4] <- json_parsed_search$address$line1
      venue_data[((i-1)*500 + 1):(i*rows), 5] <- json_parsed_search$url
      venue_data[((i-1)*500 + 1):(i*rows), 6] <- as.double(json_parsed_search$location$longitude)
      venue_data[((i-1)*500 + 1):(i*rows), 7] <- as.double(json_parsed_search$location$latitude)
    }
    
    
    Sys.sleep(2)
  }
  venue_data
}

content_1$page$totalElements

# The parameter size can take a maximum value of 500
venue_data_2 <- second.quest(country, 500, tm_key)

glimpse(venue_data_2)
``` 

## 5 Visualizing the extracted data

```{r visualization}

visualization <- function(venue_data, long_min, long_max, lat_min, lat_max, country){
  n = nrow(venue_data)
  
  for (i in 1:n){
    if (is.na(venue_data$longitude[i])) {
      
    } else if(is.na(venue_data$latitude[i])){
    
    } else if(venue_data$longitude[i] < long_min) {
      venue_data[i, 6] <- NA
      venue_data[i, 7] <- NA
    } else if (venue_data$longitude[i] > long_max) {
      venue_data[i, 6] <- NA
      venue_data[i, 7] <- NA
    } else if(venue_data$latitude[i] < lat_min) {
      venue_data[i, 6] <- NA
      venue_data[i, 7] <- NA
    } else if (venue_data$latitude[i] > lat_max){
      venue_data[i, 6] <- NA
      venue_data[i, 7] <- NA
    }
  }
  #check with row 792, whether it worked
  
  
  cap = paste("Event locations across", country)
  vis <- ggplot() + 
          geom_polygon(
            aes(x = long, y = lat, group = group), data = map_data("world", region = country),
            fill = "grey90", color = "black") + 
          theme_void() + coord_quickmap() + 
          labs(title = cap, 
               caption = "Source: ticketmaster.com") + 
          theme(title = element_text(size = 8, face = 'bold'),
                plot.caption = element_text(face = "italic")) + 
                geom_point(aes(x = longitude, y = latitude), data = venue_data,
                           na.rm = TRUE)
  
  vis
}

region = "Germany"

plot_1 <- visualization(venue_data_2, 5.866944, 15.043611, 47.271679, 55.0846, region)
plot_1
# NA-values are silently removed
```

## 6 Event location in other countries

To see the event locations in the Netherlands, the prior functions are re-used
with new parametrizations.

```{r analysisNL1}

# Task 2 and 3
country = "NL"

response_2 <- first.quest(country, tm_key)
content_2 <- content(response_2)

venue_data_3 <- first.df(response_2, content_2)

glimpse(venue_data_3)
``` 

```{r analysisNL2}

# Task 4

content_2$page$totalElements

venue_data_4 <- second.quest(country, 500, tm_key)

glimpse(venue_data_4)
```

```{r analysisNL3}

# Task 5

region = "Netherlands"

# Northernmost point in sea, but similar results
plot_2 <- visualization(venue_data_4, 3.358333, 7.227778, 50.750417, 53.555, region)
plot_2
# NA-values are silently removed
```